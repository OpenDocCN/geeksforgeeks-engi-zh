# 数据管道概述

> 原文:[https://www.geeksforgeeks.org/overview-of-data-pipeline/](https://www.geeksforgeeks.org/overview-of-data-pipeline/)

在 21 世纪的今天，我们必须处理好我们得到的每一个信息或数据。当我们通常听到管道时，我们突然想到那些将这些资源从一个地方长距离输送到另一个地方的天然气和石油管道。但是在这里，我们将了解数据管道。

**数据管道:**

数据管道处理从一端流向另一端的信息。简而言之，我们可以说从各种资源中收集数据，然后根据需求进行处理，并通过一些连续的活动将其传输到目的地。这是一组方式，首先从各种资源中提取数据，并将其转换到目的地，这意味着它处理数据，并将其从一个系统移动到另一个系统。

**为什么数据管道很重要？**

让我们考虑一个数据管道有帮助的场景。

云的改进意味着现代企业技术使用大量具有不同功能的应用程序。零售团队可能会使用枢纽现货和市场的组合来实现交易自动化。其他零售商团队主要依靠 Salesforce 来处理，其中一些可能会使用 [MangoDB](https://www.geeksforgeeks.org/mongodb-an-introduction/) 来存储客户方法。这导致不同工具之间的数据浪费，并导致数据孤岛。数据孤岛算不了什么，但它会让你很难获得商业洞察力，比如你最赚钱的市场。对于商业智能(BI)来说，在他们需要日常信息来处理的日常生活中，这一点非常重要。

**如何构建数据管道:**

一个组织可以决定要遵循的开发方法，只是为了从源中提取数据并将其传输到目的地。批量转换和处理是两种常见的开发方法。然后决定在将数据移动到所需目的地之前使用什么转换过程- [ELT(提取/加载/转换)或 ETL](https://www.geeksforgeeks.org/etl-process-in-data-warehouse/) 。

**构建数据管道面临的挑战:**

网飞已经建立了自己的数据管道。然而，构建自己的数据管道是非常困难和费时的。

以下是在内部创建数据管道的一些常见挑战:

*   centralization
*   delay

**数据管道组件:**

要深入了解数据管道如何准备大型数据集进行解构，我们必须知道它是公共数据管道的主要组件。这些是–

1.  source
2.  destination
3.  data flow
4.  deal with
5.  workflow
6.  monitor

**未来需要的改进:**

未来，世界的数据将不会被存储。这意味着在某些年份，数据将在内存中实时收集、处理和分析。这一迹象只是日益增长的改善数据管道需求背后的各种原因之一:

**最后**今天的大部分业务，数据量极高，结构动态。从这些数据的废料中创建数据管道可能是一种先进的方法，因为业务可能需要利用高质量的资源来开发它，然后确保它将随着数据量的增加和模式的变化而继续。越来越多的数据工程师在数据和业务之间架起了一座桥梁，让每个人的生活变得更加轻松。在我们最近获得的更轻松的访问背后，数据工程师付出了艰苦的努力，除了这些人之外，没有其他群体能够提供。